# Repository Organization

```
ðŸ“‚ data/                            <-- Labeled data used for training and computing metrics
ðŸ“‚ Macro_category/                  <-- Subcategory segmentation using 5 macro categories
â”‚  â”‚â”€â”€ ðŸ“‚ Inference/                <-- CSV containing the results of the inference: text + categories
â”‚  â”‚â”€â”€ ðŸ“‚ Metrics/                  <-- CSV containing the metrics for the model
â”‚  â”‚â”€â”€ ðŸ“„ Inference.py              <-- Run this to make an inference
â”‚  â”‚â”€â”€ ðŸ“„ lora_training_MACRO.py    <-- Run this to fine-tune a model on the macro categories
â”‚
ðŸ“‚ Micro_category/                  <-- Subcategory segmentation using 25 macro categories
â”‚  â”‚â”€â”€ ðŸ“‚ Inference/                <-- CSV containing the results of the inference: text + categories
â”‚  â”‚â”€â”€ ðŸ“‚ Metrics/                  <-- CSV containing the metrics for the model
â”‚  â”‚â”€â”€ ðŸ“‚ Models_comparison/        <-- Comparison of fine-tuning different models
â”‚  â”‚   â”‚â”€â”€ ðŸ“‚ Final_model/
â”‚  â”‚   â”‚   â”‚â”€â”€ ðŸ“‚ inference_final_model/          <-- Inference of the 2 best models
â”‚  â”‚   â”‚   â”‚â”€â”€ ðŸ“‚ lora_distill_llama_8b_boost2/   <-- Inference of the 2 best models
â”‚  â”‚   â”‚   â”‚â”€â”€ ðŸ“‚ lora_distill_Qwen_1.5B_boost/
â”‚  â”‚   â”‚   â”‚â”€â”€ ðŸ“„ Benchmark.csv
â”‚  â”‚   â”‚   â”‚â”€â”€ ðŸ“„ resultats_base.csv
â”‚  â”‚   â”‚   â”‚â”€â”€ ðŸ“„ resultats_lora.csv
â”‚  â”‚   â”‚â”€â”€ ðŸ“‚ original_annotation_dataset/         <-- Comparison between multiple model inferences
â”‚  â”‚   â”‚   â”‚â”€â”€ ðŸ“‚ predictions_base_model/
â”‚  â”‚   â”‚   â”‚â”€â”€ ðŸ“‚ predictions_lora_new/
â”‚  â”‚   â”‚â”€â”€ ðŸ“„ model_comparison.ipynb               <-- Metrics comparison visualized
â”‚  â”‚â”€â”€ ðŸ“„ Inference.py               <-- Run this to make an inference
â”‚  â”‚â”€â”€ ðŸ“„ lora_training.py           <-- Run this to fine-tune a model on the micro categories
â”‚  â”‚â”€â”€ ðŸ“„ Metrics_compute_2.py
â”‚
ðŸ“‚ models/                             <-- Storage of the best models
â”‚â”€â”€ ðŸ“‚ lora_distill_llama_8b_boost/    <-- Micro category model
â”‚â”€â”€ ðŸ“‚ lora_distill_Qwen_1.5B_boost/   <-- Micro category model
â”‚â”€â”€ ðŸ“‚ Macro_lora_8B/                  <-- Macro category model
â”‚
ðŸ“‚ Prompting_notebooks/               
ðŸ“‚ src/config/                        <-- Put your Hugging Face API key here
â”‚
.gitignore
â”‚
Readme.md
â”‚
requirements.txt
```

## Getting Started

1. Put your API key in a config file you will create at `src/config/config.json`:

```json
{
    "huggingface": {
        "api_token": "XXX"
    }
}
```

2. Create a virtual environment:

```sh
python3 -m venv baroclima
source baroclima/bin/activate
pip install -r requirements.txt
```

## Testing Your Trained Models with 25 Categories

```sh
python3 Micro_category/Inference.py
```

## Training a Model on Macro Categories

Modify `lora_paths`, `save_paths`, `path_data`, then run:

```sh
python3 Macro_category/lora_training_MACRO.py
```

## To Do
- Verify paths
- Automate processes

