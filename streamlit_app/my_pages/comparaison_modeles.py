import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import altair as alt

def show():
       st.title("ü§ñ Comparaison des mod√®les")
       st.write("Les mod√®les ont √©t√© compar√© sur la base de donn√©es de l'annotation originale faite par les √©tudiants de l'ann√©e pass√©e. "
              "Nous comparons dans un premier temps les performances des mod√®les entre eux et avec leur version fine-tun√©e. "
              "Le but est ensuite de garder le meilleur mod√®le et de comparer les r√©sultats avec ceux obtenus par le mod√®le de clustering semi-supervis√© qui avait √©t√© mis en place et qui utilise FastText.")
       # -------------------------
       # Chargement des CSV
       # -------------------------
       st.header("Choix du mod√®le")
       st.write("Nous avons essay√© de fine-tuner plusieurs mod√®les en open-source sur Hugging Face pour voir si nous pouvions am√©liorer les perfomances de ces petits LLMs.\n"
                "Pour des raisons de capacit√©s et de co√ªt √©nerg√©tique nous avons fait la pr√©-s√©lection sur des mod√®les charg√©s en '4-bit quantization'\n")


       # Chargement des fichiers pour l'analyse 4 bits
       df_lora_4_bits = pd.read_csv('Micro_category/Models_comparison/original_annotation_dataset/inference_lora_new/LORA_METRICS_NEW.csv')
       df_base_model_4_bits = pd.read_csv('Micro_category/Models_comparison/original_annotation_dataset/inference_base_model/METRICS_BASE_NEW.csv')

       # Chargement des fichiers pour l'analyse best/benchmark
       df_lora_best = pd.read_csv('Micro_category/Models_comparison/Final_model/resultats_lora.csv')
       df_base_best = pd.read_csv('Micro_category/Models_comparison/Final_model/resultats_base.csv')
       df_benchmark = pd.read_csv('Micro_category/Models_comparison/Final_model/Benchmark.csv')
       df_gpt = pd.read_csv('Micro_category/Models_comparison/Final_model/ChatGPT.csv')
       df_lora_4_bits = df_lora_4_bits.drop(columns=['Percentage of unsure'])
       df_base_model_4_bits = df_base_model_4_bits.drop(columns=['Percentage of unsure'])

       # Affichage c√¥te √† c√¥te
       col1, col2 = st.columns(2)

       with col1:
              st.subheader("Metrics - Lora 4 Bits")
              st.dataframe(df_lora_4_bits)

       with col2:
              st.subheader("Metrics - Base Model 4 Bits")
              st.dataframe(df_base_model_4_bits)
       # -------------------------
       # Graphiques
       # -------------------------
       # Couleurs pastel √† utiliser
       pastel_blue = "#AEC6CF"
       pastel_orange = "#FFB347"
       pastel_gray = "#CFCFC4"
       pastel_light_pink = "#FFC1C1"


       # 1. Analyse sur les CSV 4 bits
       st.subheader("Comparaison des m√©triques (4 bits)")
       metrics = ['Precision', 'Recall', 'F1_score', 'Top 1 Accuracy', 'Top 3 Accuracy']
       x = np.arange(len(metrics))  # positions des labels
       width = 0.35  # largeur des barres

       cols = st.columns(2)  # deux graphiques par ligne
       for i, model in enumerate(df_lora_4_bits.index):
              col = cols[i % 2]  # alterne entre col1 et col2
              with col:
                     fig, ax = plt.subplots(figsize=(10, 6))
                     # Graphique pour le mod√®le LoRA
                     ax.bar(x - width/1.85, df_lora_4_bits.loc[model, metrics], width,
                            label='Lora Model', color=pastel_blue)
                     # Graphique pour le mod√®le de base
                     ax.bar(x + width/1.85, df_base_model_4_bits.loc[model, metrics], width,
                            label='Base Model', color=pastel_orange)
                     
                     source = df_lora_4_bits.loc[model, "source"] if "source" in df_lora_4_bits.columns else f"Mod√®le {model}"
                     ax.set_title(f'Comparaison des m√©triques pour {source}')
                     ax.set_xlabel('M√©triques')
                     ax.set_ylabel('Valeurs')
                     ax.set_xticks(x)
                     ax.set_xticklabels(metrics)
                     ax.legend()
                     st.pyplot(fig)
                     plt.close(fig)

       # 2. Analyse sur les CSV best/benchmark
       st.header("Mod√®le retenus")
       st.write("Nous avons retenu le mod√®le Distill-Llama-8B qui a 8 milliards de apram√®tres en raison de ses performances ainsi que le mod√®le Distill-Qwen-1.5B pour √©tudier les r√©sultats d'un mod√®le plus petit.\n "
                "Ces mod√®les ont √©t√© fine tun√©s avec LoRa et charg√©s en float16 ce qui les rend entra√Ænables sur des gpu avec 24 Go de RAM. \n"
                "Nous avons compar√© les r√©sultats fine-tun√©s avec ceux des mod√®les de base ainsi qu'avec ceux obtenus par le mod√®le de FastText qui avait √©t√© mis en place et avec les r√©sultats obtenus avec GPT 3.5 Turbo (175b de param√®tres). \n")
       st.subheader("Deepseek distill llama 8B et deepseek distill qwen 1B5")
       metrics = ['Precision', 'Recall', 'F1_score', 'Top 1 Accuracy', 'Top 3 Accuracy']
       x = np.arange(len(metrics))
       width = 0.15

       cols = st.columns(2)  # deux graphiques par ligne
       for i, model in enumerate(df_lora_best.index):
              col = cols[i % 2]
              with col:
                     fig, ax = plt.subplots(figsize=(10, 6))
                     ax.bar(x - width*1.5, df_lora_best.loc[model, metrics], width,
                            label='Lora-Model', color=pastel_blue)
                     ax.bar(x - width*0.5, df_base_best.loc[model, metrics], width,
                            label='Base-Model', color=pastel_orange)
                     ax.bar(x + width*0.5, df_benchmark.loc[model, metrics], width,
                            label='Ancien model (FastText)', color=pastel_gray)
                     ax.bar(x + width*1.5, df_gpt.loc[model, metrics], width,
                            label='GPT-3.5', color=pastel_light_pink)

                     source = df_lora_best.loc[model, "source"] if "source" in df_lora_best.columns else f"Mod√®le {model}"
                     ax.set_title(f'Comparaison des m√©triques pour {source}')
                     ax.set_xlabel('M√©triques')
                     ax.set_ylabel('Valeurs')
                     ax.set_xticks(x)
                     ax.set_xticklabels(metrics)
                     ax.legend()
                     st.pyplot(fig)
                     plt.close(fig)
