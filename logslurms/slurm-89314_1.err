  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/sdim_34-89314/pip-req-build-gzuzfhcv
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/sdim_34-89314/pip-req-build-m1y2dpwa
Unused kwargs: ['bnb_8bit_compute_dtype']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.84s/it]
Map:   0%|          | 0/112 [00:00<?, ? examples/s]Map:  29%|██▊       | 32/112 [00:00<00:00, 312.07 examples/s]Map:  63%|██████▎   | 71/112 [00:00<00:00, 351.22 examples/s]Map:  99%|█████████▉| 111/112 [00:00<00:00, 367.93 examples/s]Map: 100%|██████████| 112/112 [00:00<00:00, 307.72 examples/s]
Map:   0%|          | 0/29 [00:00<?, ? examples/s]Map: 100%|██████████| 29/29 [00:00<00:00, 286.64 examples/s]
  0%|          | 0/8 [00:00<?, ?it/s]/tmp/sdim_34-89314/venv/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 12%|█▎        | 1/8 [00:10<01:11, 10.19s/it]                                              12%|█▎        | 1/8 [00:10<01:11, 10.19s/it] 25%|██▌       | 2/8 [00:23<01:13, 12.24s/it]                                              25%|██▌       | 2/8 [00:23<01:13, 12.24s/it] 38%|███▊      | 3/8 [00:32<00:53, 10.75s/it]                                              38%|███▊      | 3/8 [00:32<00:53, 10.75s/it] 50%|█████     | 4/8 [00:44<00:43, 10.97s/it]                                              50%|█████     | 4/8 [00:44<00:43, 10.97s/it] 62%|██████▎   | 5/8 [00:53<00:31, 10.42s/it]                                              62%|██████▎   | 5/8 [00:53<00:31, 10.42s/it] 75%|███████▌  | 6/8 [01:02<00:19,  9.92s/it]                                              75%|███████▌  | 6/8 [01:02<00:19,  9.92s/it] 88%|████████▊ | 7/8 [01:11<00:09,  9.73s/it]                                              88%|████████▊ | 7/8 [01:11<00:09,  9.73s/it]100%|██████████| 8/8 [01:21<00:00,  9.65s/it]                                             100%|██████████| 8/8 [01:21<00:00,  9.65s/it]                                             100%|██████████| 8/8 [01:22<00:00,  9.65s/it]100%|██████████| 8/8 [01:22<00:00, 10.26s/it]
