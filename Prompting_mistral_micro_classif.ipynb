{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, precision_score, recall_score, f1_score, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Azure OpenAI\n",
    "import os\n",
    "from langchain_openai import AzureOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"MISTRAL_API_KEY\" not in os.environ:\n",
    "    os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter your Mistral API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISTRAL_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure your mistral credentials are configured\n",
    "import getpass\n",
    "import os\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "llm = ChatMistralAI(\n",
    "    model=\"ministral-8b-latest\",\n",
    "    temperature=0,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"Gaz à effet de serre\",\n",
    "    \"Elevage et utilisation des terres\",\n",
    "    \"Pêche et chasse intensives\",\n",
    "    \"Pollution plastique\",\n",
    "    \"Déforestation\",\n",
    "    \"Surconsommation\",\n",
    "    \"Catastrophes naturelles\",\n",
    "    \"Réchauffement climatique/canicules\",\n",
    "    \"Sécheresse\",\n",
    "    \"Couche d'ozone\",\n",
    "    \"Feu de forêt\",\n",
    "    \"Tensions alimentaires/famines\",\n",
    "    \"Perte eau douce\",\n",
    "    \"Hausse des océans et fonte des glaces\",\n",
    "    \"Conséquence sociale\",\n",
    "    \"Acidification des océans\",\n",
    "    \"Biodiversité\",\n",
    "    \"Pollution\",\n",
    "    \"Energie renouvelable et nucléaire\",\n",
    "    \"Transports décarbonés\",\n",
    "    \"Engagements politiques et entreprises\",\n",
    "    \"Activisme écologique\",\n",
    "    \"Solutions innovantes\"\n",
    "    \"Comportement de consommation\",\n",
    "    \"Reforestation\",\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Réchauffement climatique/canicules'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "def classification(text, llm, categories):\n",
    "    \"\"\"\n",
    "    Function that classifies a text into a given list of categories\n",
    "\n",
    "    Arguments:\n",
    "    - text: str, the text to classify\n",
    "    - llm: AzureChatOpenAI, the language model to use\n",
    "    - categories: list, the list of categories to classify the text into\n",
    "\n",
    "    Returns:\n",
    "    - str, the category that best fits the text\n",
    "    \"\"\"\n",
    "    try: \n",
    "        prompt_message = f\"\"\"  \n",
    "            Donne uniquement la classe, parmi {categories}, qui correspond le mieux au texte donné\n",
    "            ## Règles :\n",
    "            Ne répondre qu'avec un seul terme dans {categories} .\n",
    "            ## Exemple :\n",
    "            Texte : \"Les océans absorbent trop de CO₂, ce qui perturbe la vie marine.\"\n",
    "            Réponse : {{\"category\": \"Acidification des océans\"}}\n",
    "\n",
    "            \"\"\"\n",
    "        user_message = f\"\"\"\n",
    "            Voici le texte à classifier:\n",
    "            {text}\n",
    "            \"\"\"\n",
    "        messages = [\n",
    "        SystemMessage(content=prompt_message)\n",
    "        ]\n",
    "        messages.append(\n",
    "            HumanMessage(content=user_message)\n",
    "        )\n",
    "        response = llm(messages)\n",
    "\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "text2 = \"\"\"\n",
    "La France offre l’un des plus vastes domaines skiables au monde avec 350 stations de sport d’hiver. Mais combien en restera-t-il dans 20 ans ? Avec le réchauffement climatique, la neige est plus rare en moyenne altitude, les saisons sont de plus en plus courtes et certains sites ne sont plus rentables.Il faut grimper à 1 200 mètres d’altitude, à travers les sapins du Massif central, pour le trouver. À quelques encablures d’une petite station de ski, à Chalmazel (Loire), se trouve un village vacances fantôme. Cela fait 20 ans que la résidence a fermé, et que le bâtiment rempli d’amiante est abandonné. \\Il y a eu énormément de souvenirs et d’ambiance\\\", se souvient le maire Valéry Gouttefarde, entre dépit et nostalgie. Dans les années 70, chaque bout de montagne devenait un eldorado. Des stations de ski trop petites ou trop peu enneigées Face à la concurrence des grosses stations des Alpes, la résidence difficile à chauffer est devenue passée de mode, impossible à rentabiliser. La seule solution aujourd’hui, c’est une coûteuse démolition, estimée à plus d’un million d’euros. \\\"On construisait sans se soucier du recyclage et du devenir de ces bâtiments\\\", concède le maire. Et c’est loin d’être le seul site en France à démanteler. Villages vacances vides, remontées mécaniques désaffectées... Il y aurait en tout plus de 150 stations de ski fantômes, trop petites pour survivre ou trop peu enneigées. Le site de Moutainwilderness Le site d'Installations obsolètes\"\n",
    "\"\"\"\n",
    "\n",
    "classification(text2, llm, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exemple = \"\"\"\n",
    "            Texte : \"Les émissions de CO₂ ont atteint un niveau record cette année.\"\n",
    "            Réponse JSON:\n",
    "            {{\n",
    "                \"Classe_1\": \"Gaz à effet de serre\",\n",
    "                \"Classe_2\": \"Elevage et utilisation des terres\",\n",
    "                \"Classe_3\": \"Surconsommation\"\n",
    "            }}\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solu chatgpt\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import json \n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "def classification_up_to_k(text, llm, categories, k=3, retry_attempts=5, base_delay=10):\n",
    "    \"\"\"\n",
    "    Function that classifies a text into a given list of k categories\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output_format = {f\"Classe_{i}\": \"categorie_{i}\" for i in range(1, k + 1)}\n",
    "        prompt_message = f\"\"\"\n",
    "            Donne les {k} classes, parmi {categories}, qui correspondent le mieux au texte donné, de la plus probable à la moins probable.\n",
    "            ## Règles:\n",
    "            Pour chacune des {k} prédictions, ne répondre qu'avec un seul terme dans {categories}.\n",
    "            Réponds strictement avec un dictionnaire du format JSON suivant: {output_format} où les valeurs sont des listes de catégories.\n",
    "            Les classes sont ordonnées de la plus probable à la moins probable.\n",
    "            \n",
    "        \"\"\"\n",
    "        user_message = f\"Voici le texte à classifier:\\n{text}\"\n",
    "        \n",
    "        messages = [SystemMessage(content=prompt_message), HumanMessage(content=user_message)]\n",
    "\n",
    "        for attempt in range(retry_attempts):\n",
    "            try:\n",
    "                response = llm(messages).content\n",
    "                response = \"{\" + response.partition(\"{\")[2].partition(\"}\")[0] +\"}\"\n",
    "                try:\n",
    "                    response_json = json.loads(response)  # Convertir la réponse en dictionnaire JSON\n",
    "                    return response_json  # Retourner directement le JSON valide\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Erreur : la réponse du modèle n'est pas un JSON valide.\")\n",
    "                    return None\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if e.response.status_code == 429:\n",
    "                    retry_after = int(e.response.headers.get('Retry-After', base_delay)) if 'Retry-After' in e.response.headers else base_delay\n",
    "                    print(f\"Rate limit exceeded. Retrying in {retry_after} seconds...\")\n",
    "                    time.sleep(retry_after)\n",
    "                    base_delay *= 2  # Augmenter le délai exponentiellement\n",
    "                else:\n",
    "                    print(f\"Unexpected HTTP error: {e.response.status_code}, {e.response.text}\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                return None\n",
    "        print(\"Max retry attempts reached. Returning None.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Outer exception: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_up_to_k_COT(text, llm, categories, k=3, retry_attempts=5, base_delay=10):\n",
    "    \"\"\"\n",
    "    Function that classifies a text into a given list of k categories with a reasoning\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output_format = {f\"Classe_{i}\": \"categorie_{i}\" for i in range(1, k + 1)}\n",
    "        prompt_message = f\"\"\"\n",
    "            Donne les {k} classes, parmi {categories}, qui correspondent le mieux au texte donné, de la plus probable à la moins probable. Avant cela explique ton raisonnement.\n",
    "            ## Règles:\n",
    "            Commence par un \"Raisonnement\" : ou tu expliques pourquoi tu as choisi ces classes.\n",
    "            Pour chacune des {k} prédictions, ne répondre qu'avec un seul terme dans {categories}.\n",
    "            Réponds pour les classes strictement avec un dictionnaire du format JSON suivant: {output_format} où les valeurs sont des listes de catégories\n",
    "            Les classes sont ordonnées de la plus probable à la moins probable.\n",
    "        \"\"\"\n",
    "        user_message = f\"Voici le texte à classifier:\\n{text}\"\n",
    "        \n",
    "        messages = [SystemMessage(content=prompt_message), HumanMessage(content=user_message)]\n",
    "\n",
    "        for attempt in range(retry_attempts):\n",
    "            try:\n",
    "                response = llm(messages).content\n",
    "                response = \"{\" + response.partition(\"{\")[2].partition(\"}\")[0] +\"}\"\n",
    "                try:\n",
    "                    response_json = json.loads(response)  # Convertir la réponse en dictionnaire JSON\n",
    "                    return response_json  # Retourner directement le JSON valide\n",
    "                except json.JSONDecodeError:\n",
    "                    print(response)\n",
    "                    print(\"Erreur : la réponse du modèle n'est pas un JSON valide.\")\n",
    "                    return None\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if e.response.status_code == 429:\n",
    "                    retry_after = int(e.response.headers.get('Retry-After', base_delay)) if 'Retry-After' in e.response.headers else base_delay\n",
    "                    print(f\"Rate limit exceeded. Retrying in {retry_after} seconds...\")\n",
    "                    time.sleep(retry_after)\n",
    "                    base_delay *= 2  # Augmenter le délai exponentiellement\n",
    "                else:\n",
    "                    print(f\"Unexpected HTTP error: {e.response.status_code}, {e.response.text}\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                return None\n",
    "        print(\"Max retry attempts reached. Returning None.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Outer exception: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_up_to_k_CARP(text, llm, categories, k=3, retry_attempts=5, base_delay=10):\n",
    "    \"\"\"\n",
    "    Function that classifies a text into a given list of k categories with a reasoning\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output_format = {f\"Classe_{i}\": \"categorie_{i}\" for i in range(1, k + 1)}\n",
    "        prompt_message = f\"\"\"\n",
    "            Donne les {k} classes, parmi {categories}, qui correspondent le mieux au texte donné, de la plus probable à la moins probable. Avant cela explique ton raisonnement.\n",
    "            ## Règles:\n",
    "            Commence par Indices une liste d'INDICES pris dans le texte fourni (c'est-à-dire de mots-clés, de phrases, d'informations contextuelles, de relations sémantiques, de sens sémantique, de tonalités, de références) qui soutiennent la détermination des classes.\n",
    "            Puis fais un Raisonnement déduire le processus de RAISONNEMENT diagnostique à partir des prémisses (c'est-à-dire les indices, l'entrée) qui soutiennent la détermination des classes du texte (limiter le nombre de mots à 130).\n",
    "            Pour chacune des {k} prédictions, ne répondre qu'avec un seul terme dans {categories}.\n",
    "            Réponds pour les classes strictement avec un dictionnaire du format JSON suivant: {output_format} où les valeurs sont des listes de catégories.\n",
    "            Les classes sont ordonnées de la plus probable à la moins probable.\n",
    "        \"\"\"\n",
    "        user_message = f\"Voici le texte à classifier:\\n{text}\"\n",
    "        \n",
    "        messages = [SystemMessage(content=prompt_message), HumanMessage(content=user_message)]\n",
    "\n",
    "        for attempt in range(retry_attempts):\n",
    "            try:\n",
    "                response = llm(messages).content\n",
    "                response = \"{\" + response.partition(\"{\")[2].partition(\"}\")[0] +\"}\"\n",
    "                try:\n",
    "                    response_json = json.loads(response)  # Convertir la réponse en dictionnaire JSON\n",
    "                    return response_json  # Retourner directement le JSON valide\n",
    "                except json.JSONDecodeError:\n",
    "                    print(response)\n",
    "                    print(\"Erreur : la réponse du modèle n'est pas un JSON valide.\")\n",
    "                    return None\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if e.response.status_code == 429:\n",
    "                    retry_after = int(e.response.headers.get('Retry-After', base_delay)) if 'Retry-After' in e.response.headers else base_delay\n",
    "                    print(f\"Rate limit exceeded. Retrying in {retry_after} seconds...\")\n",
    "                    time.sleep(retry_after)\n",
    "                    base_delay *= 2  # Augmenter le délai exponentiellement\n",
    "                else:\n",
    "                    print(f\"Unexpected HTTP error: {e.response.status_code}, {e.response.text}\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                return None\n",
    "        print(\"Max retry attempts reached. Returning None.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Outer exception: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Classe_1': 'Gaz à effet de serre',\n",
       " 'Classe_2': 'Transports décarbonés',\n",
       " 'Classe_3': 'Engagements politiques et entreprises'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"\"\"\n",
    "\"en france, les transports sont responsables de 32% des émissions de gaz à effet de serre\" : françois gemenne veut décarboner aussi nos routes cette semaine on s’intéresse à l’alliance pour la décarbonation de la route, une initiative lancée, le 12 décembre 2023, par françois gemenne avec plusieurs collègues et universitaires. c’est un regroupement de chercheurs, d’industriels et de collectivités, qui veulent travailler à décarboner la route, et à mettre en œuvre des solutions concrètes pour réduire les émissions de gaz à effet de serre provoquées par le trafic routier. franceinfo : pourquoi la route ? pourquoi c’est important ? parce que c’est la principale source d’émissions de gaz à effet de serre en france. en france, selon le haut conseil pour le climat, les émissions du secteur des transports sont responsables de 32% des émissions. et l’immense majorité de ces émissions, elles sont provoquées par le transport routier : 94% des émissions de transports en france, ce sont les voitures, les camions et les véhicules utilitaires. et surtout c’est un secteur dont les émissions ne baissent guère, contrairement à d’autres secteurs comme l’industrie et le bâtiment. selon l’agence européenne de l’environnement, les émissions du secteur des transports seront en 2030 supérieures de 10% à leur niveau de 1990. il y a la voiture électrique, pourtant… bien sûr. et c’est important, mais ça ne suffit pas. parce qu’il y a aussi la question des infrastructures, de la route elle-même. si on n’équipe pas les infrastructures, si on ne permet pas davantage de report modal, par exemple, si on n’investit pas davantage dans le transport public, on n’y arrivera pas. \"si on ne s’attaque pas à la route, on ne parviendra jamais à atteindre notre objectif de réduction des émissions de 55% d’ici 2030, au niveau national.\" et donc, comment peut-on faire ? le problème, c’est que dès qu’on s’attache à la voiture, les français ont l’impression qu’on s’attaque à leur liberté individuelle, et on voit que le soutien des français aux mesures qui touchent à la voiture est de plus en plus faible. ce que nous disons, c’est qu’il faut décarboner la route elle-même, et pas seulement les véhicules qui roulent dessus. mais est-ce que la solution ce n’est pas le train, tout simplement ? le report modal, vers le train notamment, ou vers le vélo pour les courts trajets, fait évidemment partie de la solution. mais aujourd’hui, l’écrasante majorité des déplacements du quotidien continuent à se faire en voiture, et même dans des voitures dans lesquelles on voyage seul. donc il faut absolument s’attaquer à ces émissions-là. comment peut-on faire ? quelles sont les solutions ? la bonne nouvelle, c’est qu’il y a énormément de solutions, et que ces solutions ne demandent qu’à être mises en œuvre. il y a la transformation de nos routes et de nos autoroutes, mais aussi des solutions de transport collectif : par exemple des cars express dans des régions rurales ou semi-rurales. ou des lignes de co-voiturage, pour permettre aux gens de partager leur voiture. il y a plein de choses qu’on peut faire. des solutions techniques ou technologiques, mais aussi des solutions d’usages, de pratiques, d’aménagements urbains ou d’aménagements routiers… pourquoi est-ce qu’on ne le fait pas, alors ? \"la route a souvent été le parent pauvre de nos politiques de décarbonation.\" c’est pour ça que nous lançons cette alliance : pour faire travailler ensemble tous les gens qui ont des solutions et qui veulent les mettre en œuvre. des constructeurs automobiles, des concessionnaires d’autoroutes, des professionnels du co-voiturage, des exploitants de transport collectif, des entreprises du btp, des assurances, en lien avec les collectivités, bien entendu. l’idée, c’est de proposer des solutions concrètes, et de voir ensuite avec les pouvoirs publics comment il est possible de les mettre en œuvre. et on invite tous ceux qui sont intéressés, qui ont des solutions à proposer, à nous rejoindre.\n",
    "\"\"\"\n",
    "classification_up_to_k(text3, llm, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = \"\"\"\n",
    "agriculture : changer les habitudes face au réchauffement climatique l’agriculture est responsable d’un quart des émissions de gaz à effet de serre, constate le giec (groupement d’experts intergouvernemental sur l’évolution du climat). les experts préconisent une agriculture raisonnée et de modifier notre alimentation. faut-il manger moins de viande ? dans son rapport de 1 200 pages, le giec (groupement d’experts intergouvernemental sur l’évolution du climat) préconise de revoir les pratiques agricoles car l’agriculture émet 24 % des gaz à effet de serre. \"on constate que les activités humaines se sont déployées sur les trois quarts des sols de notre planète. au cours des dernières décennies, l'humanité a intensifié l’utilisation des terres et l’exploitation de l’eau potable\", constate marc chardonnens, directeur de l’office fédéral de l’environnement (ofev) réduire la viande la demande va augmenter avec la population. la planète va passer de 7 milliards de personnes en 2019 à 9,8 milliards en 2050. de plus en plus de bouches à nourrir donc, alors que la terre est à bout de souffle. des pistes sont étudiées : rendre à la forêt des zones d'élevage de ruminants ou changer de régime alimentaire comme réduire la viande et les produits laitiers. il ne faudrait pas dépasser 33 kg par an. or, en france, nous en consommons 260 kg par an.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Elevage et utilisation des terres\"'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(4)\n",
    "classification(text4, llm, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Classe_1': 'Elevage et utilisation des terres',\n",
       " 'Classe_2': 'Gaz à effet de serre',\n",
       " 'Classe_3': 'Surconsommation'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(4)\n",
    "classification_up_to_k(text4, llm, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Classe_1': 'Elevage et utilisation des terres',\n",
       " 'Classe_2': 'Gaz à effet de serre',\n",
       " 'Classe_3': 'Conséquence sociale'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(4)\n",
    "classification_up_to_k_COT(text4, llm, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Classe_1': 'Gaz à effet de serre',\n",
       " 'Classe_2': 'Elevage et utilisation des terres',\n",
       " 'Classe_3': 'Surconsommation'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(4)\n",
    "classification_up_to_k_CARP(text4, llm, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inférence Mistral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification multi-label avec score de confiance entre 0 et 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On demande ici à Mistral de prédire 3 classes avec un degré de confiance pour chacune. Ce degré de confiance est un nombre entre 0 et 1 et peut être vu comme une probabilité d'appartenance à chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = \"./annotation_sous_thematiques.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_raw = [\"\"\" Texte:\n",
    "                agriculture : changer les habitudes face au réchauffement climatique l’agriculture est responsable d’un quart des émissions de gaz à effet de serre, constate le giec (groupement d’experts intergouvernemental sur l’évolution du climat). les experts préconisent une agriculture raisonnée et de modifier notre alimentation. faut-il manger moins de viande ? dans son rapport de 1 200 pages, le giec (groupement d’experts intergouvernemental sur l’évolution du climat) préconise de revoir les pratiques agricoles car l’agriculture émet 24 % des gaz à effet de serre. \"on constate que les activités humaines se sont déployées sur les trois quarts des sols de notre planète. au cours des dernières décennies, l'humanité a intensifié l’utilisation des terres et l’exploitation de l’eau potable\", constate marc chardonnens, directeur de l’office fédéral de l’environnement (ofev) réduire la viande la demande va augmenter avec la population. la planète va passer de 7 milliards de personnes en 2019 à 9,8 milliards en 2050. de plus en plus de bouches à nourrir donc, alors que la terre est à bout de souffle. des pistes sont étudiées : rendre à la forêt des zones d'élevage de ruminants ou changer de régime alimentaire comme réduire la viande et les produits laitiers. il ne faudrait pas dépasser 33 kg par an. or, en france, nous en consommons 260 kg par an.\n",
    "Réponse :\n",
    "{\n",
    "  \"Classe_1\": \"Gaz à effet de serre\",\n",
    "  \"Classe_2\": \"Elevage et utilisation des terres\",\n",
    "  \"Classe_3\": \"Comportement de consommation\"\n",
    "}\n",
    "\"\"\",\"\"\"2\"\"\",\"\"\"3\"\"\",\"\"\"\"\"\"]\n",
    "examples_COT = [\"\"\" Texte:\n",
    "                agriculture : changer les habitudes face au réchauffement climatique l’agriculture est responsable d’un quart des émissions de gaz à effet de serre, constate le giec (groupement d’experts intergouvernemental sur l’évolution du climat). les experts préconisent une agriculture raisonnée et de modifier notre alimentation. faut-il manger moins de viande ? dans son rapport de 1 200 pages, le giec (groupement d’experts intergouvernemental sur l’évolution du climat) préconise de revoir les pratiques agricoles car l’agriculture émet 24 % des gaz à effet de serre. \"on constate que les activités humaines se sont déployées sur les trois quarts des sols de notre planète. au cours des dernières décennies, l'humanité a intensifié l’utilisation des terres et l’exploitation de l’eau potable\", constate marc chardonnens, directeur de l’office fédéral de l’environnement (ofev) réduire la viande la demande va augmenter avec la population. la planète va passer de 7 milliards de personnes en 2019 à 9,8 milliards en 2050. de plus en plus de bouches à nourrir donc, alors que la terre est à bout de souffle. des pistes sont étudiées : rendre à la forêt des zones d'élevage de ruminants ou changer de régime alimentaire comme réduire la viande et les produits laitiers. il ne faudrait pas dépasser 33 kg par an. or, en france, nous en consommons 260 kg par an.\n",
    "Réponse :\n",
    "    Gaz à effet de serre : Le texte souligne que l'agriculture est responsable de 24 % des émissions de gaz à effet de serre, ce qui est un indicateur clair de cette catégorie.\n",
    "    Elevage et utilisation des terres : Le texte discute de l'utilisation intensive des terres pour l'élevage et l'agriculture, ce qui correspond directement à cette catégorie.\n",
    "    Comportement de consommation : Le texte propose de modifier les habitudes alimentaires, notamment en réduisant la consommation de viande, ce qui relève du comportement de consommation.\n",
    "{\n",
    "  \"Classe_1\": \"Gaz à effet de serre\",\n",
    "  \"Classe_2\": \"Elevage et utilisation des terres\",\n",
    "  \"Classe_3\": \"Comportement de consommation\"\n",
    "}\n",
    "\"\"\",\"\"\"2\"\"\",\"\"\"3\"\"\",\"\"\"\"\"\"]\n",
    "examples_CARP = [\"\"\"\n",
    "Texte:\n",
    "    agriculture : changer les habitudes face au réchauffement climatique l’agriculture est responsable d’un quart des émissions de gaz à effet de serre, constate le giec (groupement d’experts intergouvernemental sur l’évolution du climat). les experts préconisent une agriculture raisonnée et de modifier notre alimentation. faut-il manger moins de viande ? dans son rapport de 1 200 pages, le giec (groupement d’experts intergouvernemental sur l’évolution du climat) préconise de revoir les pratiques agricoles car l’agriculture émet 24 % des gaz à effet de serre. \"on constate que les activités humaines se sont déployées sur les trois quarts des sols de notre planète. au cours des dernières décennies, l'humanité a intensifié l’utilisation des terres et l’exploitation de l’eau potable\", constate marc chardonnens, directeur de l’office fédéral de l’environnement (ofev) réduire la viande la demande va augmenter avec la population. la planète va passer de 7 milliards de personnes en 2019 à 9,8 milliards en 2050. de plus en plus de bouches à nourrir donc, alors que la terre est à bout de souffle. des pistes sont étudiées : rendre à la forêt des zones d'élevage de ruminants ou changer de régime alimentaire comme réduire la viande et les produits laitiers. il ne faudrait pas dépasser 33 kg par an. or, en france, nous en consommons 260 kg par an.\n",
    "Réponse :\n",
    "\n",
    "Indices:\n",
    "\"l'agriculture est responsable d’un quart des émissions de gaz à effet de serre\",\"les activités humaines se sont déployées sur les trois quarts des sols de notre planète\",\"réduire la viande et les produits laitiers\",\"rendre à la forêt des zones d'élevage de ruminants\",\"l'humanité a intensifié l’utilisation des terres et l’exploitation de l’eau potable\"\n",
    "Raisonnement:\n",
    "Gaz à effet de serre : Le texte mentionne explicitement que l'agriculture est responsable de 24 % des émissions de gaz à effet de serre, ce qui justifie cette catégorie.\n",
    "Elevage et utilisation des terres : Le texte parle de l'utilisation intensive des terres pour l'élevage et l'agriculture, soulignant l'impact sur les sols et l'exploitation des ressources\n",
    "Comportement de consommation : Le texte propose de modifier les habitudes alimentaires, notamment en réduisant la consommation de viande et de produits laitiers, ce qui relève directement du comportement de consommation.\n",
    "\n",
    "Voici les classes correspondantes :\n",
    "\n",
    "{\n",
    "  \"Classe_1\": \"Gaz à effet de serre\",\n",
    "  \"Classe_2\": \"Elevage et utilisation des terres\",\n",
    "  \"Classe_3\": \"Comportement de consommation\"\n",
    "}\n",
    "\"\"\",\"\"\"2\"\"\",\"\"\"3\"\"\",\"\"\"\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_message(output_format,k, categories ,prompt_method,n_shots,recursive=False,previous_answer = \"\"):\n",
    "    if prompt_method == \"raw\":\n",
    "        prompt_message = f\"\"\"\n",
    "            Donne les classes, parmi {categories}, qui correspondent le mieux au texte donné.\n",
    "            ## Règles:\n",
    "            Pour chacune des {k} prédictions, ne répondre qu'avec un seul terme dans {categories}\n",
    "            Réponds pour les classes strictement avec un dictionnaire du format JSON suivant: {output_format} où les valeurs sont des listes de catégories.\n",
    "            Les classes sont ordonnées de la plus probable à la moins probable.\n",
    "        \"\"\" \n",
    "        prompt_message +=  '\\n'.join(examples_raw[:n_shots])\n",
    "    elif prompt_method == \"COT\":\n",
    "        prompt_message = f\"\"\"\n",
    "            Donne les {k} classes, parmi {categories}, qui correspondent le mieux au texte donné, de la plus probable à la moins probable. Avant cela explique ton raisonnement.\n",
    "            ## Règles:\n",
    "            Fais un Raisonnement déduire le processus de RAISONNEMENT diagnostique à partir des prémisses (c'est-à-dire les indices, l'entrée) qui soutiennent la détermination des classes du texte (limiter le nombre de mots à 130).\n",
    "            Pour chacune des {k} prédictions, ne répondre qu'avec un seul terme dans {categories}.\n",
    "            Réponds pour les classes strictement avec un dictionnaire du format JSON suivant: {output_format} où les valeurs sont des listes de catégories.\n",
    "            Les classes sont ordonnées de la plus probable à la moins probable.\n",
    "        \"\"\"\n",
    "        prompt_message +=  '\\n'.join(examples_COT[:n_shots])\n",
    "    elif prompt_method == \"CARP\":\n",
    "        prompt_message = f\"\"\"\n",
    "            Donne les {k} classes, parmi {categories}, qui correspondent le mieux au texte donné, de la plus probable à la moins probable. Avant cela explique ton raisonnement.\n",
    "            ## Règles:\n",
    "            Commence par Indices une liste d'INDICES pris dans le texte fourni (c'est-à-dire de mots-clés, de phrases, d'informations contextuelles, de relations sémantiques, de sens sémantique, de tonalités, de références) qui soutiennent la détermination des classes.\n",
    "            Puis fais un Raisonnement déduire le processus de RAISONNEMENT diagnostique à partir des prémisses (c'est-à-dire les indices, l'entrée) qui soutiennent la détermination des classes du texte (limiter le nombre de mots à 130).\n",
    "            Pour chacune des {k} prédictions, ne répondre qu'avec un seul terme dans {categories}.\n",
    "            Réponds pour les classes strictement avec un dictionnaire du format JSON suivant: {output_format} où les valeurs sont des listes de catégories.\n",
    "            Les classes sont ordonnées de la plus probable à la moins probable.\n",
    "        \"\"\"\n",
    "        prompt_message +=  '\\n'.join(examples_CARP[:n_shots])\n",
    "    \n",
    "    if recursive :\n",
    "        prompt_message += '\\n' + f\"{previous_answer}\"\n",
    "    return prompt_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_up_to_k_general(text, llm,categories,prompt_method = \"raw\",n_shots=0,k = 3,retry_attempts=5, base_delay=10):\n",
    "    \"\"\"\n",
    "    Function that classifies a text into a given list of k categories with a reasoning\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output_format = {f\"Classe_{i}\": \"categorie_{i}\" for i in range(1, k + 1)}\n",
    "        prompt_message = get_prompt_message(output_format,k, categories ,prompt_method,n_shots)\n",
    "        user_message = f\"Voici le texte à classifier:\\n{text}\"\n",
    "        messages = [SystemMessage(content=prompt_message), HumanMessage(content=user_message)]\n",
    "\n",
    "        for attempt in range(retry_attempts):\n",
    "            try:\n",
    "                response = llm(messages).content\n",
    "                response = \"{\" + response.partition(\"{\")[2].partition(\"}\")[0] +\"}\"\n",
    "                try:\n",
    "                    response_json = json.loads(response)  # Convertir la réponse en dictionnaire JSON\n",
    "                    return response_json  # Retourner directement le JSON valide\n",
    "                except json.JSONDecodeError:\n",
    "                    print(response)\n",
    "                    print(\"Erreur : la réponse du modèle n'est pas un JSON valide.\")\n",
    "                    return None\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if e.response.status_code == 429:\n",
    "                    retry_after = int(e.response.headers.get('Retry-After', base_delay)) if 'Retry-After' in e.response.headers else base_delay\n",
    "                    print(f\"Rate limit exceeded. Retrying in {retry_after} seconds...\")\n",
    "                    time.sleep(retry_after)\n",
    "                    base_delay *= 2  # Augmenter le délai exponentiellement\n",
    "                else:\n",
    "                    print(f\"Unexpected HTTP error: {e.response.status_code}, {e.response.text}\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                return None\n",
    "        print(\"Max retry attempts reached. Returning None.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Outer exception: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_up_to_k_recursive(text, llm,categories,prompt_method = \"raw\",n_shots=0,k = 3,retry_attempts=5, base_delay=10 , n_iter = 1):\n",
    "    prompt = classification_up_to_k_general(text, llm,categories,prompt_method,n_shots,k,retry_attempts, base_delay)\n",
    "    for i in range(n_iter): \n",
    "        time.sleep(4) \n",
    "        output_format = {f\"Classe_{i}\": \"categorie_{i}\" for i in range(1, k + 1)}\n",
    "        prompt_message = get_prompt_message(output_format,k, categories ,prompt_method,n_shots,recursive=True,previous_answer = prompt)\n",
    "        user_message = f\"Voici le texte à classifier:\\n{text}\"\n",
    "        messages = [SystemMessage(content=prompt_message), HumanMessage(content=user_message)]\n",
    "\n",
    "        for attempt in range(retry_attempts):\n",
    "            try:\n",
    "                response = llm(messages).content\n",
    "                response = \"{\" + response.partition(\"{\")[2].partition(\"}\")[0] +\"}\"\n",
    "            except:\n",
    "                return None\n",
    "        \n",
    "        prompt_message += \"\\n\" + response\n",
    "    try:\n",
    "        response_json = json.loads(response)  # Convertir la réponse en dictionnaire JSON\n",
    "        return response_json  # Retourner directement le JSON valide\n",
    "    except json.JSONDecodeError:\n",
    "        print(response)\n",
    "        print(\"Erreur : la réponse du modèle n'est pas un JSON valide.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Classe_1': 'Gaz à effet de serre',\n",
       " 'Classe_2': 'Elevage et utilisation des terres',\n",
       " 'Classe_3': 'Surconsommation'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_up_to_k_recursive(text4, llm, categories, prompt_method = \"COT\", n_shots=0, k = 3, retry_attempts=5, base_delay=10 , n_iter = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_pred(path_df = \"./annotation_sous_thematiques.csv\" ,classification = classification_up_to_k_general,recursive = False,prompt_method = \"raw\",model=\"ministral8b\",n_shots = 0):\n",
    "    df = pd.read_csv(path_df)\n",
    "    df = df.head(400)\n",
    "    df = df[df['label']==1]\n",
    "    df.shape\n",
    "    df[\"prediction_label\"] = None\n",
    "    events_count = df.shape[0]\n",
    "    k = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        df.at[idx, \"prediction_label\"] = classification(row[\"description\"], llm, categories,prompt_method,n_shots)\n",
    "        time.sleep(4)  # Attendre 4 secondes entre chaque requête   \n",
    "        \n",
    "        if k % 28 == 0 and k > 0:\n",
    "            finished = 100*(k/events_count)\n",
    "            print('Finished processing {} % of all events'.format(int(finished)))\n",
    "        k+=1\n",
    "    df = df[df['prediction_label'].notna()]\n",
    "    try:\n",
    "        for i in range(1,4):\n",
    "            df[f\"prediction_label{i}\"] = df[\"prediction_label\"].apply(lambda x: x[f\"Classe_{i}\"])\n",
    "    except KeyError:\n",
    "        print(\"KeyError\")\n",
    "    if recursive:\n",
    "        path_pred = \"./predictions_141articles_{}_{}_{}shots_recursive.csv\".format(model,prompt_method,n_shots)\n",
    "    else:\n",
    "        path_pred = \"./predictions_141articles_{}_{}_{}shots.csv\".format(model,prompt_method,n_shots)\n",
    "    df.to_csv(path_pred, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculs métriques "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionnaires utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping pour faire coïncider les noms codés des labels avec les prédictions\n",
    "mapping = {\n",
    "    \"Gaz à effet de serre\": \"gaz_effet_de_serre\",\n",
    "    \"Elevage et utilisation des terres\": \"agriculture_et_utilisation_du_sol\",\n",
    "    \"Pêche et chasse intensives\": \"peche_et_chasse\",\n",
    "    \"Pollution plastique\": \"pollution\",\n",
    "    \"Déforestation\": \"deforestation\",\n",
    "    \"Surconsommation\": \"surconsommation\",\n",
    "    \"Catastrophes naturelles\": \"catastrophes_naturelles\",\n",
    "    \"Réchauffement climatique/canicules\": \"rechauffement_climatique_canicule\",\n",
    "    \"Sécheresse\": \"secheresse\",\n",
    "    \"Couche d'ozone\": \"couche_ozone\",\n",
    "    \"Feu de forêt\": \"feu_foret\",\n",
    "    \"Tensions alimentaires/famines\": \"tension_alim_famines\",\n",
    "    \"Perte eau douce\": \"eau_potable\",\n",
    "    \"Hausse des océans et fonte des glaces\": \"hausse_niveau_mer_fonte_glace\",\n",
    "    \"Conséquence sociale\": \"consequence_sociale\",\n",
    "    \"Acidification des océans\": \"acidification_ocean\",\n",
    "    \"Biodiversité\": \"perte_biodiversite\",\n",
    "    \"Pollution\": \"pollution\",\n",
    "    \"Energie renouvelable et nucléaire\": \"energies_renouvelables_et_nucleaires\",\n",
    "    \"Transports décarbonés\": \"transport_decarbone\",\n",
    "    \"Engagements politiques et entreprises\": \"engagement_politique_et_entreprises\",\n",
    "    \"Activisme écologique\": \"activisme_eco\",\n",
    "    \"Solutions innovantes\": \"solution_innovante\",\n",
    "    \"Comportement de consommation\": \"comportement_consommateur\",\n",
    "    \"Reforestation\": \"reforestation\"\n",
    "}\n",
    "\n",
    "\n",
    "# Cause\n",
    "# Gaz à effet de serre\n",
    "gaz_effet_de_serre = [\"co2\", \"méthane\", \"protoxyde\", \"azote\" \"oxyde\", \"nitreux\", \"ozone\", \"chlorofluorocarbones\", \"hydrofluorocarbones\", \"perfluorocarbones\", \"soufre\",\n",
    "                    \"hexafluorure\", \"gaz\", \"émissions\", \"serre\", \"carbone\", \"dioxyde\", \"air\", \"fossile\"]\n",
    "\n",
    "# Utilisation des terres\n",
    "agriculture_et_utilisation_du_sol = [\"agriculture\", \"sol\", \"changement\", \"érosion\", \"désertification\", \"dégradation\", \"aérosol\", \"pulvérisation\", \"bétail\",\n",
    "                         \"agricultures\", \"vache\", \"bovin\", \"culture\", \"rendement\", \"récolte\", \"engrais\", \"pesticide\", \"labour\"]\n",
    "\n",
    "# Pêches et chasses\n",
    "peche_et_chasse = [\"poisson\", \"pêche\", \"chasse\", \"baleine\", \"disparition\", \"extinction\", \"espèces\", \"surpêche\", \"surchasse\", \"quota\", \"capture\",\n",
    "                   \"prédateur\"]\n",
    "\n",
    "# Intrant chimique / pollution plastique\n",
    "intrants_chimique_pollution_plastique = [\"plastique\", \"pollution\", \"microplastique\", \"microplastiques\", \"plastiques\", \"déchets\", \"ordures\", \"détritus\",\n",
    "                                         \"recyclage\", \"recycler\", \"chimique\", \"décharge\", \"industrielle\", \"contamination\", \"engrais\"]\n",
    "\n",
    "# Surconsommation\n",
    "surconsommation = [\"surconsommation\", \"consommation\", \"comportement\", \"achat\", \"compulsif\", \"gaspillage\", \"excès\", \"superflu\", \"masse\", \"hyperconsommation\"\n",
    "                   \"style\", \"vie\", \"possession\", \"dépenser\", \"frénésie\"]\n",
    "\n",
    "# Déforestation\n",
    "deforestation = [\"déforestation\", \"forêt\", \"déboiser\", \"déforestier\", \"végétation\", \"arbre\", \"arbres\", \"végétal\", \"exploitation\", \"défrichement\",\n",
    "                 \"défricher\", \"abattage\"]\n",
    "\n",
    "cause_thematiques = {\"gaz_effet_de_serre\": gaz_effet_de_serre,\n",
    "                    \"agriculture_et_utilisation_du_sol\": agriculture_et_utilisation_du_sol,\n",
    "                    \"peche_et_chasse\": peche_et_chasse,\n",
    "                    \"intrants_chimique_pollution_plastique\": intrants_chimique_pollution_plastique,\n",
    "                    \"surconsommation\": surconsommation,\n",
    "                    \"deforestation\": deforestation}\n",
    "\n",
    "\n",
    "# Conséquences\n",
    "# Catastrophes naturelles\n",
    "catastrophes_naturelles = [\"catastrophe\", \"naturelle\", \"inondation\", \"catastrophique\", \"phénomène\", \"cyclone\", \"séisme\",\n",
    "                            \"ouragan\", \"tempête\", \"dérégulation\", \"climatologie\", \"grêle\", \"vent\", \"typhon\", \"tornade\", \"tsunami\"]\n",
    "\n",
    "# Réchauffement climatique / canicule\n",
    "rechauffement_climatique_canicule = [\"réchauffement\", \"climatique\", \"chauffage\", \"température\", \"chaleur\", \"canicule\",\n",
    "                                     \"chaud\", \"adaptation\", \"thermomètre\", \"extrême\", \"caniculaire\"]\n",
    "\n",
    "# Sécheresse\n",
    "secheresse = [\"pénurie\", \"aridité\", \"déficit\", \"assèchement\", \"sols\", \"manque\", \"precipitations\", \"réserves\", \"désert\", \"sécheresse\", \"désertique\",\n",
    "              \"déshydratation\", \"irrigation\", \"humidité\"]\n",
    "\n",
    "# Couche d'ozone\n",
    "couche_ozone = [\"ozone\", \"appauvrissement\", \"trous\", \"chlorofluorocarbures\", \"Halons\", \"ultraviolet\", \"nocif\", \"rayonnement\", \"stratosphère\"]\n",
    "\n",
    "# Feu de forêt\n",
    "feu_foret = [\"incendies\", \"feu\", \"forêt\", \"pompier\", \"incontrôlé\", \"propagation\", \"fumée\", \"brulée\", \"étendue\", \"ardent\", \"incondescent\", \"pyromane\"]\n",
    "\n",
    "# Tension alimentaires / famines\n",
    "tension_alim_famines = [\"insécurité\", \"alimentaire\", \"famine\", \"malnutrition\", \"crise\", \"rareté\", \"besoins\", \"déficit\", \"sécurité\", \"affamé\", \"pénurie\"]\n",
    "\n",
    "# Perte d'eau douce\n",
    "eau_potable = [\"eau\", \"douce\", \"fraîche\", \"potable\", \"boire\", \"potable\", \"potabilité\", \"dégradation\", \"qualité\", \"crise\", \"raréfaction\",\n",
    "               \"nappes\", \"phréatiques\", \"courante\", \"cristalline\", \"filtration\", \"purification\", \"assainissement\"]\n",
    "\n",
    "# Hausse du niveau de la mer et fontes des glaces\n",
    "hausse_niveau_mer_fonte_glace = [\"hausse\", \"mer\", \"océan\", \"océanique\", \"niveau\", \"fonte\", \"montée\", \"élévation\", \"côte\", \"marée\",\n",
    "                                 \"bloc\", \"glace\", \"iceberg\", \"glacier\", \"permafrost\", \"banquise\", \"dégel\"]\n",
    "\n",
    "# Conséquences sociales\n",
    "consequence_sociale = [\"logement\", \"population\", \"déplacement\", \"conflit\", \"migration\", \"instabilité\", \"sociale\", \"mentale\", \"inégalité\", \"santé\",\n",
    "                       \"mode\", \"vie\", \"pauvreté\", \"communauté\", \"vulnérabilité\", \"précarité\", \"exclusion\", \"dépendance\", \"société\", \"humain\"]\n",
    "\n",
    "# Acidification océan\n",
    "acidification_ocean = [\"acidification\", \"acidité\", \"pH\", \"carbonate\", \"calcium\", \"coraux\", \"marins\", \"mollusques\", \"coquilles\", \"plankton\", \"acidose\",\n",
    "                       \"océan\"]\n",
    "\n",
    "# Perte de biodiversité\n",
    "perte_biodiversite = [\"biodiversité\", \"espèces\", \"extinction\", \"disparition\", \"animaux\", \"plante\", \"végétation\", \"sauvage\", \"menacées\", \"menacé\",\n",
    "                     \"récolte\", \"cultures\", \"écologie\", \"marine\", \"terre\", \"réserve\", \"habitat\", \"corail\", \"écosystème\", \"conservation\", \n",
    "                     \"fragilité\", \"urgence\"]\n",
    "\n",
    "# Pollution\n",
    "pollution = [\"air\", \"eau\", \"sol\", \"émissions\", \"gaz\", \"pollution\", \"polluant\", \"déchet\", \"toxique\", \"atmosphérique\", \"contamination\", \"industriel\",\n",
    "             \"chimique\", \"résidus\", \"dégradation\", \"détritus\"]\n",
    "\n",
    "consequence_thematiques = {\"catastrophes_naturelles\":catastrophes_naturelles,\n",
    "                           \"rechauffement_climatique_canicule\":rechauffement_climatique_canicule,\n",
    "                            \"secheresse\":secheresse,\n",
    "                            \"couche_ozone\":couche_ozone,\n",
    "                            \"feu_foret\":feu_foret,\n",
    "                            \"tension_alim_famines\":tension_alim_famines,\n",
    "                            \"eau_potable\":eau_potable,\n",
    "                            \"hausse_niveau_mer_fonte_glace\":hausse_niveau_mer_fonte_glace,\n",
    "                            \"consequence_sociale\":consequence_sociale,\n",
    "                            \"acidification_ocean\":acidification_ocean,\n",
    "                            \"perte_biodiversite\":perte_biodiversite,\n",
    "                            \"pollution\":pollution}\n",
    "\n",
    "\n",
    "# Solutions\n",
    "# Énergies renouvelables et nucléaires\n",
    "energies_renouvelables_et_nucleaires = [\"renouvelable\", \"solaire\", \"éolien\", \"biomasse\", \"géothermique\", \"hydraulique\", \"hydroélectrique\", \"photovoltaïque\",\n",
    "                                \"durabilité\", \"transition\", \"nucléaire\", \"propre\", \"thermique\", \"durable\", \"électricité\", \"électrique\", \"puissance\",\n",
    "                                \"stockage\", \"fission\", \"fusion\"]\n",
    "\n",
    "# Transport décarbonés\n",
    "transport_decarbone = [\"véhicule\", \"électrique\", \"batterie\", \"commun\", \"transport\", \"hybride\", \"covoiturage\", \"vélo\", \"hydrogène\", \"aménagement\", \"mobilité\",\n",
    "                       \"routier\", \"ferroviaire\", \"électrification\"]\n",
    "\n",
    "# Engagement politique et entreprises\n",
    "engagement_politique_et_entreprises = [\"gouvernance\", \"législation\", \"accord\", \"engagement\", \"stratégie\", \"diplomatie\", \"acteurs\", \"lobbying\", \"participation\",\n",
    "                                     \"responsabilité\", \"traités\", \"financement\", \"Paris\", \"régulation\", \"organisations\", \"politique\", \"économie\",\n",
    "                                     \"projet\", \"loi\", \"certification\", \"investissement\"]\n",
    "\n",
    "# Activisme écologique\n",
    "activisme_eco = [\"militantisme\", \"mouvement\", \"écologie\", \"marches\", \"protestation\", \"défense\", \"environnement\", \"activisme\", \"engagement\", \"protection\",\n",
    "                 \"grève\", \"boycott\", \"mobilisation\", \"plaidoyer\", \"désobéissance\", \"civile\", \"dénonciation\", \"dénoncer\", \"action\", \"manifestation\"]\n",
    "\n",
    "# Solutions innovantes\n",
    "solution_innovante = [\"technologie\", \"verte\", \"innovation\", \"développement\", \"produit\", \"nouvelle\", \"approche\", \"technologie\", \"propre\", \"recherche\",\n",
    "                      \"écoconception\", \"circulaire\", \"créativité\", \"créatif\", \"alternatif\", \"solution\"]\n",
    "\n",
    "# Comportement de consommation\n",
    "comportement_consommateur = [\"consommateur\", \"consommation\", \"comportement\", \"style\", \"vie\", \"responsable\", \"durable\", \"minimalisme\", \"consciente\",\n",
    "                             \"équitable\", \"éthique\", \"locaux\", \"collaborative\", \"collectivité\", \"astuce\"]\n",
    "\n",
    "# Reforestation\n",
    "reforestation = [\"reboisement\", \"plantation\", \"replantation\", \"arbre\", \"reforestation\", \"carbone\", \"lutte\", \"régénération\", \"régénérer\", \"restauration\",\n",
    "                 \"forêt\", \"biodiversité\", \"reconstitution\", \"sylviculture\", \"boisement\", \"repeuplement\", \"repeupler\"]\n",
    "\n",
    "solution_thematiques = {\"energies_renouvelables_et_nucleaires\": energies_renouvelables_et_nucleaires,\n",
    "                        \"transport_decarbone\": transport_decarbone,\n",
    "                        \"engagement_politique_et_entreprises\": engagement_politique_et_entreprises,\n",
    "                        \"activisme_eco\": activisme_eco,\n",
    "                        \"solution_innovante\": solution_innovante,\n",
    "                        \"comportement_consommateur\": comportement_consommateur,\n",
    "                        \"reforestation\": reforestation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_labels(labels, mapping):\n",
    "    \"\"\"\n",
    "    Formate les labels en utilisant le mapping, mais conserve les labels déjà formatés.\n",
    " \n",
    "    Arguments :\n",
    "    - labels : list, la liste des labels à formater.\n",
    "    - mapping : dict, le dictionnaire de correspondance des labels.\n",
    "\n",
    "    Retourne :\n",
    "    - list, la liste des labels formatés.\n",
    "    \"\"\"\n",
    "    formatted_labels = []\n",
    "    for label in labels:\n",
    "        # Si le label est déjà dans le bon format (valeur du mapping), on le conserve\n",
    "        if label in mapping.values():\n",
    "                formatted_labels.append(label)\n",
    "        # Sinon, on utilise le mapping pour le formater\n",
    "        else:\n",
    "            formatted_label = mapping.get(label, \"N/A\")\n",
    "            if formatted_label != \"N/A\":\n",
    "                formatted_labels.append(formatted_label)\n",
    "    return formatted_labels\n",
    "\n",
    "def get_perf(df_results, pred_col):\n",
    "\n",
    "    y_true = df_results[\"label\"]\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    full_dic = cause_thematiques | consequence_thematiques | solution_thematiques\n",
    "    mlb.fit([pd.Series(list(full_dic.keys())).unique()])\n",
    "    mlb.classes_\n",
    "\n",
    "    y_true_binarized = mlb.transform(y_true)\n",
    "    y_pred = df_results[pred_col]\n",
    "    y_pred_binarized = mlb.transform(y_pred)\n",
    "    \n",
    "    def top3_accuracy(preds, labels):\n",
    "        for pred in preds:\n",
    "            if pred in labels:\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    def top1_accuracy(preds, labels):\n",
    "        if len(preds) == 0:\n",
    "            return 0\n",
    "        \n",
    "        elif preds[0] in labels:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    df_score_global = pd.DataFrame({\"Precision\": [precision_score(y_true_binarized, y_pred_binarized, average='weighted')*100],\n",
    "                                              \n",
    "                                \"Recall\": [recall_score(y_true_binarized, y_pred_binarized, average='weighted')*100],\n",
    "                                              \n",
    "                                \"F1_score\": [f1_score(y_true_binarized, y_pred_binarized, average='weighted')*100],\n",
    "                                \"Top 1 Accuracy\": [round(df_results.apply(lambda x: top1_accuracy(x[pred_col], x[\"label\"]), axis=1).sum()/len(df_results)*100,2)],\n",
    "                                \"Top 3 Accuracy\": [round(df_results.apply(lambda x: top3_accuracy(x[pred_col], x[\"label\"]), axis=1).sum()/len(df_results)*100,2)],\n",
    "                                \"Percentage of unsure\": [round(df_results.apply(lambda x: 1 if len(x[pred_col])==0 else 0, axis=1).sum()/len(df_results)*100,2)]                     \n",
    "                                })\n",
    "\n",
    "    return df_score_global.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: [WinError 10054] Une connexion existante a dû être fermée par l’hôte distant\n",
      "Finished processing 19 % of all events\n",
      "Finished processing 39 % of all events\n",
      "Finished processing 59 % of all events\n",
      "Finished processing 79 % of all events\n",
      "Finished processing 99 % of all events\n",
      "KeyError\n",
      "Done_ministral8b_CARP_1shots\n"
     ]
    }
   ],
   "source": [
    "modèles = [\"ministral8b\"]\n",
    "prompt_methods = [\"CARP\"]\n",
    "number_shots = [1]\n",
    "paths = []\n",
    "for model in modèles:\n",
    "    for prompt_method in prompt_methods:\n",
    "        for n_shot in number_shots:\n",
    "            get_df_pred(path_df = path_df,classification = classification_up_to_k_general,prompt_method = prompt_method,model = model,n_shots= n_shot)\n",
    "            paths.append(\"./predictions_141articles_{}_{}_{}shots.csv\".format(model,prompt_method,n_shot))\n",
    "            print(f\"Done_{model}_{prompt_method}_{n_shot}shots\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe(path):\n",
    "        df = pd.read_csv(path)\n",
    " \n",
    "        # Create a copy to avoid SettingWithCopyWarning\n",
    "           \n",
    "        df_results = df[\n",
    "            [\"description\", \"label_1\", \"label_2\", \"label_3\",\n",
    "            \"prediction_label_1\", \"prediction_label_2\", \"prediction_label_3\"]\n",
    "        ].copy()\n",
    "        # Format true labels\n",
    "        df_results[\"label\"] = df_results[[\"label_1\", \"label_2\", \"label_3\"]].apply(\n",
    "            lambda x: format_labels(x.dropna().tolist(), mapping), axis=1\n",
    "        )\n",
    "        # Format predicted labels\n",
    "        df_results[\"pred_label\"] = df_results[\n",
    "            [\"prediction_label_1\", \"prediction_label_2\", \"prediction_label_3\"]\n",
    "        ].apply(\n",
    "            lambda x: format_labels(x.dropna().tolist(), mapping), axis=1\n",
    "        )\n",
    "        # Affiche les labels bruts avant de les passer à format_labels\n",
    " \n",
    " \n",
    "        # Count hallucinations (N/A in predictions)\n",
    "        counter = sum(1 for preds in df_results[\"pred_label\"] if \"N/A\" in preds)\n",
    "        print(f\"Nombre de documents avec une hallucination: {counter}\")\n",
    "        return get_perf(df_results, \"pred_label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths.append(\"./predictions_141articles_ministral8b_COT_0shots.csv\")\n",
    "paths.append(\"./predictions_141articles_ministral8b_CARP_0shots.csv\")\n",
    "paths.append(\"./predictions_141articles_ministral8b_COT_1shots.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./predictions_141articles_ministral8b_COT_1shots.csv',\n",
       " './predictions_141articles_ministral8b_CARP_1shots.csv',\n",
       " './predictions_141articles_ministral8b_CARP_0shots.csv',\n",
       " './predictions_141articles_ministral8b_COT_0shots.csv']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = list(set(paths))\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    df['prediction_label_1'] = df[\"prediction_label\"].apply(lambda x: ast.literal_eval(x)['Classe_1'])\n",
    "    df['prediction_label_2'] = df[\"prediction_label\"].apply(lambda x: ast.literal_eval(x)[\"Classe_2\"])\n",
    "    df['prediction_label_3'] = df[\"prediction_label\"].apply(lambda x: ast.literal_eval(x)[\"Classe_3\"])\n",
    "    df2 = df.T.drop_duplicates().T\n",
    "    df.to_csv(path, index=False)\n",
    "path = \"./predictions_141articles_ministral8b_COT_1shots.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./predictions_141articles_ministral8b_COT_1shots.csv\n",
      "Nombre de documents avec une hallucination: 0\n",
      "./predictions_141articles_ministral8b_CARP_1shots.csv\n",
      "Nombre de documents avec une hallucination: 0\n",
      "./predictions_141articles_ministral8b_CARP_0shots.csv\n",
      "Nombre de documents avec une hallucination: 0\n",
      "./predictions_141articles_ministral8b_COT_0shots.csv\n",
      "Nombre de documents avec une hallucination: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Top 1 Accuracy</th>\n",
       "      <th>Top 3 Accuracy</th>\n",
       "      <th>Percentage of unsure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ministral8b_COT_1shots</th>\n",
       "      <td>51.97</td>\n",
       "      <td>60.23</td>\n",
       "      <td>50.83</td>\n",
       "      <td>61.70</td>\n",
       "      <td>87.23</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ministral8b_CARP_1shots</th>\n",
       "      <td>50.06</td>\n",
       "      <td>56.87</td>\n",
       "      <td>47.07</td>\n",
       "      <td>63.57</td>\n",
       "      <td>82.86</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ministral8b_CARP_0shots</th>\n",
       "      <td>53.87</td>\n",
       "      <td>53.41</td>\n",
       "      <td>44.30</td>\n",
       "      <td>54.61</td>\n",
       "      <td>82.27</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ministral8b_COT_0shots</th>\n",
       "      <td>52.30</td>\n",
       "      <td>54.92</td>\n",
       "      <td>44.60</td>\n",
       "      <td>61.70</td>\n",
       "      <td>85.82</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatgpt_ancien</th>\n",
       "      <td>51.64</td>\n",
       "      <td>54.25</td>\n",
       "      <td>46.51</td>\n",
       "      <td>63.04</td>\n",
       "      <td>81.88</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Precision  Recall  F1_score  Top 1 Accuracy  Top 3 Accuracy  Percentage of unsure\n",
       "ministral8b_COT_1shots       51.97   60.23     50.83           61.70           87.23                  0.00\n",
       "ministral8b_CARP_1shots      50.06   56.87     47.07           63.57           82.86                  0.00\n",
       "ministral8b_CARP_0shots      53.87   53.41     44.30           54.61           82.27                  0.00\n",
       "ministral8b_COT_0shots       52.30   54.92     44.60           61.70           85.82                  0.00\n",
       "chatgpt_ancien               51.64   54.25     46.51           63.04           81.88                  1.45"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for path in paths:\n",
    "    print(path)\n",
    "    df_result = pipe(path)  \n",
    "    \n",
    "    if df_result is not None and not df_result.empty:  \n",
    "        filename = os.path.basename(path)  \n",
    "        index_name = \"_\".join(filename.replace(\".csv\", \"\").split(\"_\")[-3:]) \n",
    "\n",
    "        df_result[\"source\"] = index_name  \n",
    "        result = pd.concat([result, df_result], ignore_index=True)\n",
    "\n",
    "result.set_index(\"source\", inplace=True)\n",
    "\n",
    "new_data = pd.DataFrame([[51.64, 54.25, 46.51, 63.04, 81.88, 1.45]], \n",
    "                        columns=result.columns, \n",
    "                        index=[\"chatgpt_ancien\"])\n",
    "\n",
    "result = pd.concat([result, new_data])\n",
    "\n",
    "result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
